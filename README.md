
# DataAnalyst-Vijaya
Project Portfolio for the 311 Inquiry Volume for the City of Vancouver
# Project Title 
Exploratory Data Analysis (EDA) Initiative for 311 Inquiry Volume for the City of Vancouver
# Project Description 
The Exploratory Data Analysis (EDA) Initiative aims to gain in-depth insights from the 311 Inquiry Volume dataset by transforming raw data into valuable information that can be used to enhance public services. This involves securely storing the data in AWS S3, applying data cleaning and validation techniques with AWS Glue, and analyzing the dataset using AWS Athena to identify patterns, trends, and relationships. By leveraging AWS services, the project enables the City of Vancouver to make data-driven decisions based on accurate, comprehensive insights derived from the 2023 and 2024 inquiry records.
# Objective
The objective of this project is to comprehensively process, clean, and validate the 311 Inquiry Volume dataset to ensure that the data is of high quality, secure, and reliable for analysis. Through Exploratory Data Analysis (EDA), the project will uncover critical patterns and trends within the inquiry data, such as inquiry types, volume fluctuations, and departmental workloads. The project ensures efficient data handling by utilizing AWS services like S3, Glue, and Athena. It enables the City of Vancouver to make informed decisions that enhance public service efficiency and responsiveness based on data-driven insights.
# Dataset
The dataset is a part of the 311 Inquiry Volume project for the City of Vancouver for the years 2023 and 2024, and it includes information about the following:
-	**Department**: Likely the department to which the inquiry was directed.
-	**Type**: The type of inquiry.
-	**Year Month**: The date the inquiry was made.
-	**Channel**: The communication method used (e.g., phone, chat).
-	**Number of Records**: The count of inquiries.
-	**BI_ID**: A unique identifier for each record.

# Background
The 311 Inquiry Volume dataset contains public inquiries about the City of Vancouver through various channels. This project involves processing the 2023 and 2024 datasets to ensure they are well-organized, accurate, and ready for exploratory analysis. The data is cleaned, transformed, and analyzed using AWS tools like Glue, Athena, and S3 to uncover trends and provide meaningful insights.
# Scope
-  Ingest and store the 311 Inquiry Volume dataset in AWS S3.
-  Perform data cleaning and transformation using AWS Glue.
-  Conduct exploratory data analysis using AWS Athena.
-  Use data visualization to uncover trends and insights.
-  Automate the data pipeline for consistent updates and analysis.

![Project1](https://github.com/Vijaya397/Data-Analyst-Vijaya/blob/main/Images/Project1_Draw.io.jpg?raw=true
)


![Big Data Framework](https://github.com/your-github-username/your-repo-name/blob/main/images/bcframework.png)

## [Project 3: Analysing Big Data streams in Cluster](https://link-to-your-paper-or-github)
In this project, a framework was designed and implemented for the efficient analysis of Big Data streams using cluster resources.  
- Improved the efficiency of the analysis by up to 65%.
- A distributed cluster of 32 computing nodes was implemented using Linux, Storm, Java, and Python.
- All evaluations were executed on the implemented cluster with real-world scenarios.

![Cluster Analysis Framework](https://github.com/your-github-username/your-repo-name/blob/main/images/cluster_framework.png)
