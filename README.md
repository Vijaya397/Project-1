
# DataAnalyst-Vijaya
Project Portfolio for the 311 Inquiry Volume for the City of Vancouver
# Project Title 
Exploratory Data Analysis (EDA) Initiative for 311 Inquiry Volume for the City of Vancouver
# Project Description 
The Exploratory Data Analysis (EDA) Initiative aims to gain in-depth insights from the 311 Inquiry Volume dataset by transforming raw data into valuable information that can be used to enhance public services. This involves securely storing the data in AWS S3, applying data cleaning and validation techniques with AWS Glue, and analyzing the dataset using AWS Athena to identify patterns, trends, and relationships. By leveraging AWS services, the project enables the City of Vancouver to make data-driven decisions based on accurate, comprehensive insights derived from the 2023 and 2024 inquiry records.
# Objective
The objective of this project is to comprehensively process, clean, and validate the 311 Inquiry Volume dataset to ensure that the data is of high quality, secure, and reliable for analysis. Through Exploratory Data Analysis (EDA), the project will uncover critical patterns and trends within the inquiry data, such as inquiry types, volume fluctuations, and departmental workloads. The project ensures efficient data handling by utilizing AWS services like S3, Glue, and Athena. It enables the City of Vancouver to make informed decisions that enhance public service efficiency and responsiveness based on data-driven insights.
# Dataset
The dataset is a part of the 311 Inquiry Volume project for the City of Vancouver for the years 2023 and 2024, and it includes information about the following:
-	**Department**: Likely the department to which the inquiry was directed.
-	**Type**: The type of inquiry.
-	**Year Month**: The date the inquiry was made.
-	**Channel**: The communication method used (e.g., phone, chat).
-	**Number of Records**: The count of inquiries.
-	**BI_ID**: A unique identifier for each record.

## [Project 2: Analysing Big Data streams in Cloud](https://link-to-your-paper-or-github)
In this project, a framework is designed and implemented for the efficient analysis of Big Data streams using public cloud resources.  
- Five algorithms were designed, implemented, and evaluated using real case scenarios.
- Modules were implemented using Java and Python languages.
- Improved analysis efficiency by up to 41%.  

![Big Data Framework](https://github.com/your-github-username/your-repo-name/blob/main/images/bcframework.png)

## [Project 3: Analysing Big Data streams in Cluster](https://link-to-your-paper-or-github)
In this project, a framework was designed and implemented for the efficient analysis of Big Data streams using cluster resources.  
- Improved the efficiency of the analysis by up to 65%.
- A distributed cluster of 32 computing nodes was implemented using Linux, Storm, Java, and Python.
- All evaluations were executed on the implemented cluster with real-world scenarios.

![Cluster Analysis Framework](https://github.com/your-github-username/your-repo-name/blob/main/images/cluster_framework.png)
